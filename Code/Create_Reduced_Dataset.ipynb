{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e51a1a9",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3068a532",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f275db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f1f73",
   "metadata": {},
   "source": [
    "**Generate balanced dataset of ~10,000 dives and non-dives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aadf941",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps07_gv37846_20190206_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps11_gv37849_20190206_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps10_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps12_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps16_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps03_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps13_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps08_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps09_S1/...\n",
      "\n",
      "Time elapsed: 2311.46582698822\n",
      "\n",
      "Stacking and shuffling...\n",
      "Bringing into memory...\n",
      "Writing to csv...\n"
     ]
    }
   ],
   "source": [
    "birds = glob.glob('../Data/Acc_npy/*/')\n",
    "\n",
    "arrs = []\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "for bird in birds:\n",
    "    \n",
    "    print(f'PROCESSING BIRD: {bird}...')\n",
    "    \n",
    "    # Load data\n",
    "    data = da.from_npy_stack(bird)\n",
    "    \n",
    "    # Sample dives\n",
    "    dive_ix = da.where(data[:,-1] == 1)[0].compute()\n",
    "    pos = data[da.random.choice(dive_ix, random.randint(1000, 1250), replace=False)]\n",
    "\n",
    "    # Sample non-dives\n",
    "    no_dive_ix = np.setdiff1d(np.arange(data.shape[0]), dive_ix)\n",
    "    neg = data[da.random.choice(no_dive_ix, random.randint(1150, 1400), replace=False)]\n",
    "\n",
    "    # Stack, shuffle, and add to list\n",
    "    data_add = da.vstack((pos, neg))\n",
    "    arrs.append(data_add)\n",
    "    \n",
    "print(f'\\nTime elapsed: {time.time() - t}')\n",
    "    \n",
    "print('\\nStacking and shuffling...')\n",
    "data_full = da.vstack(arrs)  # stack\n",
    "ix = np.random.choice(data_full.shape[0], data_full.shape[0], replace=False)\n",
    "data_full = da.slicing.shuffle_slice(data_full, ix)  # shuffle    \n",
    "\n",
    "# split into train/test\n",
    "print('\\rSplitting into train/test...')\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = data_full[msk]\n",
    "test = data_full[~msk]\n",
    "\n",
    "# Save in npy stack\n",
    "print('\\rWriting to npy stack...')\n",
    "da.to_npy_stack('../Data/Reduced/npy_train/', train, axis=0)\n",
    "da.to_npy_stack('../Data/Reduced/npy_test/', test, axis=0)\n",
    "\n",
    "# Convert to df and write to csv\n",
    "print('\\rBringing into memory...')\n",
    "df_train = train.to_dask_dataframe().compute()\n",
    "df_test = test.to_dask_dataframe().compute()\n",
    "\n",
    "df_train.iloc[:, -1] = df_train.iloc[:, -1].astype(int)\n",
    "df_test.iloc[:, -1] = df_test.iloc[:, -1].astype(int)\n",
    "\n",
    "# write to csv\n",
    "print('\\rWriting to csv...')\n",
    "df_train.to_csv('../Data/Reduced/train_reduced_dset.csv', header=False, index=False)\n",
    "df_test.to_csv('../Data/Reduced/test_reduced_dset.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3615ff",
   "metadata": {},
   "source": [
    "## With bird ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f948eda7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps07_gv37846_20190206_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps11_gv37849_20190206_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps10_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps12_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps16_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps03_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps13_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps08_S1/...\n",
      "PROCESSING BIRD: ../Data/Acc_npy/ch_gps09_S1/...\n",
      "\n",
      "Time elapsed: 2292.1076719760895\n",
      "\n",
      "Stacking and shuffling...\n",
      "Writing to csv...\n"
     ]
    }
   ],
   "source": [
    "birds = glob.glob('../Data/Acc_npy/*/')\n",
    "\n",
    "dfs = []\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "for bird in birds:\n",
    "    \n",
    "    print(f'PROCESSING BIRD: {bird}...')\n",
    "    \n",
    "    idd = bird.split('/')[-2]\n",
    "    \n",
    "    # Load data\n",
    "    data = da.from_npy_stack(bird)\n",
    "    \n",
    "    # Sample dives\n",
    "    dive_ix = da.where(data[:,-1] == 1)[0].compute()\n",
    "    pos = data[da.random.choice(dive_ix, random.randint(1000, 1250), replace=False)]\n",
    "\n",
    "    # Sample non-dives\n",
    "    no_dive_ix = np.setdiff1d(np.arange(data.shape[0]), dive_ix)\n",
    "    neg = data[da.random.choice(no_dive_ix, random.randint(1150, 1400), replace=False)]\n",
    "\n",
    "    # Stack, compute, and add to list\n",
    "    data_add = dd.from_dask_array(da.vstack((pos, neg))).compute()\n",
    "    data_add.columns = [*data_add.columns[:-1], 'Dive']  # rename last col\n",
    "    data_add['Dive'] = data_add['Dive'].astype(int)\n",
    "    data_add['BirdID'] = idd\n",
    "    \n",
    "    dfs.append(data_add)\n",
    "    \n",
    "print(f'\\nTime elapsed: {time.time() - t}')\n",
    "    \n",
    "print('\\nStacking and shuffling...')\n",
    "data_full = pd.concat(dfs, ignore_index=True) # stack\n",
    "data_full = data_full.sample(frac=1) # shuffle\n",
    "\n",
    "print('Writing to csv...')\n",
    "data_full.to_csv('../Data/Reduced/reduced_dset_wnames.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd07781a",
   "metadata": {},
   "source": [
    "# From npz stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd5ffbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3049179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../Data/Acc/ch_gps03_S1/6.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "279db00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = '../Data/Acc/ch_gps03_S1/0.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cd3dc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Acc/ch_gps03_S1/9.npz',\n",
       " '../Data/Acc/ch_gps03_S1/11.npz',\n",
       " '../Data/Acc/ch_gps03_S1/20.npz',\n",
       " '../Data/Acc/ch_gps03_S1/22.npz',\n",
       " '../Data/Acc/ch_gps03_S1/19.npz',\n",
       " '../Data/Acc/ch_gps03_S1/4.npz',\n",
       " '../Data/Acc/ch_gps03_S1/6.npz',\n",
       " '../Data/Acc/ch_gps03_S1/0.npz']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('../Data/Acc/ch_gps03_S1/*.npz')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "730b3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_npz(filename):\n",
    "    \"\"\"Loads and withdraws dive data from npz file\n",
    "    \"\"\"\n",
    "    idd = filename.split('/')[-2]\n",
    "    \n",
    "    # Load\n",
    "    data = np.load(filename)\n",
    "    data = data[data.files[0]]\n",
    "    \n",
    "    # Sample all dives\n",
    "    pos = data[data[:,-1] == 1, :]\n",
    "\n",
    "    # Sample non-dives\n",
    "    no_dive_ix = np.where(data[:,-1] == 0)[0]\n",
    "    neg = data[np.random.choice(no_dive_ix, random.randint(200, 250), replace=False)]\n",
    "\n",
    "    # Stack, compute, and add to list\n",
    "    data_add = pd.DataFrame(np.vstack((pos, neg)))\n",
    "    data_add.columns = [*data_add.columns[:-1], 'Dive']  # rename last col\n",
    "    data_add['Dive'] = data_add['Dive'].astype(int)\n",
    "    data_add['BirdID'] = idd\n",
    "    \n",
    "    return data_add\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dee5730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Pool() as pool:\n",
    "    dfs = list(pool.map(process_npz, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e99d12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf8632",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = glob.glob('../Data/Acc_npy/*/')  #!\n",
    "\n",
    "dfs = []\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "for bird in birds:\n",
    "    \n",
    "    print(f'PROCESSING BIRD: {bird}...')\n",
    "    \n",
    "    idd = bird.split('/')[-2]\n",
    "    \n",
    "    # Load data\n",
    "    \n",
    "    data = da.from_npy_stack(bird)\n",
    "    \n",
    "    # Sample dives\n",
    "    dive_ix = da.where(data[:,-1] == 1)[0].compute()\n",
    "    pos = data[da.random.choice(dive_ix, random.randint(1000, 1250), replace=False)]\n",
    "\n",
    "    # Sample non-dives\n",
    "    no_dive_ix = np.setdiff1d(np.arange(data.shape[0]), dive_ix)\n",
    "    neg = data[da.random.choice(no_dive_ix, random.randint(1150, 1400), replace=False)]\n",
    "\n",
    "    # Stack, compute, and add to list\n",
    "    data_add = dd.from_dask_array(da.vstack((pos, neg))).compute()\n",
    "    data_add.columns = [*data_add.columns[:-1], 'Dive']  # rename last col\n",
    "    data_add['Dive'] = data_add['Dive'].astype(int)\n",
    "    data_add['BirdID'] = idd\n",
    "    \n",
    "    dfs.append(data_add)\n",
    "    \n",
    "print(f'\\nTime elapsed: {time.time() - t}')\n",
    "    \n",
    "print('\\nStacking and shuffling...')\n",
    "data_full = pd.concat(dfs, ignore_index=True) # stack\n",
    "data_full = data_full.sample(frac=1) # shuffle\n",
    "\n",
    "print('Writing to csv...')\n",
    "data_full.to_csv('../Data/Reduced/reduced_dset_wnames.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
