\documentclass[11pt]{article}
% \documentclass[tikz]{standalone}

\usepackage{pgfgantt}
\usepackage[margin=2cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{lineno}
\usepackage{setspace}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear,open={(},close={)}}

\usepackage{array}
\newcolumntype{P}[1]{>{\raggedright\arraybackslash}p{#1}}

\usepackage{caption} 
\captionsetup[table]{skip=10pt}

\newcommand{\reporttitle}{Can We Predict Diving Behaviour In Pelagic Seabirds From Immersion Data?}
\newcommand{\reportauthor}{Luke Swaby}
\newcommand{\reportsupervisor}{Robin Freeman (ZSL)}
\newcommand{\reportcosupervisor}{Matteo Fumagalli}
\newcommand{\reportcid}{01980806}
\newcommand{\degreetype}{Master of Science}

\begin{document}
  \begin{onehalfspace}
  \input{Frontpage.tex} % front page
  \section{Introduction}
    Anthropogenic pressures such as pollution, climate change, and depletion of prey resulting from overfishing are causing sharp declines in seabird populations worldwide \citep{croxall2012seabird,paleczny2015population}.
    As recognised biological indicators, the welfare of these species is indicative of the states of the marine ecosystems they depend on, and so data on their behaviour at sea can accordingly be used to identify key areas and inform conservation strategies \citep{einoder2009review,mallory2010seabirds}. However, direct observation of these elusive animals can be challenging, and only recently have technological developments in telemetry enabled us to break free from the epistemic constraints of sparse presence/absence data and truly pull back the curtain on their lives over the open ocean \citep{guilford2009migration,maclean2013evaluating}. Longitudinal movement data has been especially valuable in identifying diving behaviour associated with foraging \citep{guilford2008gps}. This data is typically collected using a combination of global positioning systems (GPS) and cumbersome time-depth recorders (TDR). Somewhat eliminating the need for the latter, however, it has been demonstrated by \cite{browning2018predicting} that dive behaviour can be accurately predicted from GPS data alone using deep learning, which was shown in the same study to provide greater predictive power than traditional behavioural prediction methods such as hidden Markov models. 
    
    While preferable to the costly and cumbersome TDR, GPS devices still have significant limitations. Beyond having a relatively short battery life of just a few months, GPS loggers weigh around 10-12g and must be back-mounted, accordingly imposing a considerable impediment on the birds wearing them. Another device carried by a substantial number of the birds currently monitored is the geolocator — a small 3g leg-mounted device equipped with light and wet/dry sensors, with a battery life lasting years. If similar insights can be derived from this less obstructive and more continuous form of data collection then this would enable researchers to collect and analyse much more data at a lower cost to both themselves and the birds wearing the devices. To that end, this study intends to use deep learning to investigate whether immersion data collected from 9 Red-Footed Boobies in the Chagos Archipelago can be used to predict dive behaviour — and thus foraging locations — in pelagic seabirds.
    
    It is worth noting that in the case that immersion data fails to predict diving behaviour, an alternative form of data is available that, while not quite as convenient to collect as the immersion data, would still provide a preferable alternative to GPS data for this method. In addition to GPS, time-depth, and immersion data, there is also 25Hz accelerometer data available for each individual. If it can be shown that this data can be used to accurately predict dives, then this could inform future deployments as well, such as, say, tiny accelerometers fitted onto birds in addition to the immersion loggers. However, this will be considered only if the more ideal immersion data fails.

  \vspace{\baselineskip} 
  \textbf{Keywords:} seabirds; conservation; foraging; behaviour; machine learning; deep learning; 
  
  \section{Proposed Methods}
    Basic Outline:

    \begin{itemize}
      \item \textbf{Data Preparation}: First, gather the datasets and assign diving profiles. This will likely consist of analysing depth data for spikes that exceed a predetermined threshold — chosen to distinguish between genuine diving events and background noise — then separating these dive events into bouts and recording their locations. The data will then be divided into a training set and a validation set, and wrangled into a format appropriate for training a deep neural network. 
      \item \textbf{Model Fitting}: Next, determine optimal network type and structure and pass the training data set into some deep learning code (language/software to use still yet to be decided, but options include Python, R, and H2O). Given that the data is temporal (i.e. there is inherent dependency), the use of Keras/Tensorflow to implement a convolutional network may be appropriate here. I will have to learn how to build these models and interpret their outputs. 
      \item \textbf{Model Validation and Optimization}: Finally, test the model predictions against the withheld validation data set and tweak the model if need be. Options here include modifying its structure and investigating the effect of withholding certain variables on its predictive accuracy.
      \item \textbf{Results Roll Out:} If the methods are successful, then they can be applied to another 10 birds with immersion loggers and no GPS, providing further demonstration of the methodology. 
    \end{itemize}

  \section{Anticipated Outcomes}
    By the end of this study, we aim to have:

    \begin{itemize}
      \item A conclusive answer on the feasibility of identifying foraging locations using immersion data only.
      \item An additional quantitative and qualitative evaluation of the capacity of deep learning to predict animal behavior.
    \end{itemize}
    
  
  \section{Timeline of Tasks}
    \begin{figure}[H]
      \centerline{\includegraphics[height=8cm]{GANTTY.pdf}}
      \caption{\small Project workflow.}
    \end{figure}
  
  \section{Itemised budget}
  
  \begin{table}[ht]
    \caption{Itemised Budget} % title of Table
    \centering % used for centering table
    \begin{tabular}{ |P{0.15\linewidth}|P{0.22\linewidth}|P{0.45\linewidth}|c| } % centered columns (3 columns)
    \hline %inserts double horizontal lines
    \textbf{Category} & \textbf{Item} & \textbf{Justification} & \textbf{Price (£)} \\ [0.5ex] % inserts table
    %heading
    \hline % inserts single horizontal line
    Computing Power & 1TB SSD & Quick manipulation of large datasets. & 120 \\
    \cline{2-2} \cline{3-3} \cline{4-4}
    & HPC & Additional computing power. Exact amount required unknown. & 0 (?) \\
    \hline
    Workspace Improvement & External keyboard and mouse & Help prevent physical complications arising from extended periods working exclusively with a laptop keyboard (I have a history of carpal tunnel syndrome). & 50 \\ [1ex] % [1ex] adds vertical space
    \cline{2-2} \cline{3-3} \cline{4-4}
    & Monitor & To extend my work area beyond my 13" laptop screen. & 60 \\
    \hline
    Specialist Skills Development & Machine Learning Textbook & Gain required specialist computing skills. & 40 \\ 
    \cline{2-2} \cline{3-3} \cline{4-4}
    & Deep Learning Online Course & Gain required specialist computing skills. & 105 \\
    \hline
    
    \hline %inserts single line
    \end{tabular}
    \label{table:nonlin} % is used to refer this table in the text
  \end{table}
  
  \section{Supervisor Declaration}
  
  %\vspace*{\fill}
  \begingroup
  \centering
  \textbf{``I have seen and approved the proposal and the budget''}
  
  \bigskip 
  
  \centering
  Name: \textcolor{blue}{\large Robin Freeman}
  
  \vspace{\baselineskip} 
  \centering
  Date: \textcolor{blue}{09/04/2021}
 
  
  \endgroup
  %\vspace*{\fill}
  
  \bibliography{Biblio.bib}
  \end{onehalfspace}
  
\end{document}